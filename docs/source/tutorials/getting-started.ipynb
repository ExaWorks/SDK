{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Background\n",
    "PSI/J (Portable Submission Interface for Jobs), is a Python abstraction layer which allows your HPC application to run virtually anywhere. <br> <br>\n",
    "![psij-overview-visual](./images/psij-overview.png)\n",
    "<br>\n",
    "<br>\n",
    "PSI/J automatically translates abstract job specifications into concrete scripts and commands to send to the scheduler. PSI/J has a number of advantages:\n",
    "1. **Runs entirely in user space**: no need to wait for infrequent deployment cycles, it's easy to leverage built-in or community-provided plugins\n",
    "2. **An asynchronous modern API for job management**: a clean Python API for requesting and managing jobs.\n",
    "3. **Supports the common batch schedulers**: we test PSI/J across multiple DOE supercomputer centers. It’s easy to test PSI/J on your systems and share the results with the community.\n",
    "4. **Built by the HPC community, for the HPC community**: PSI/J is based on a number of libraries used by state-of-the-art HPC workflow applications.\n",
    "5. **PSI/J is an open source project**: we are establishing a community to develop, test, and deploy PSI/J across many HPC facilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install from pip ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!bash -c \"pip install psij-python\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... Or Install from Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!bash -c \"python3 --version\"\n",
    "!bash -c \"python3 -m venv psij-tutorial-venv\"\n",
    "!bash -c \"source ./psij-tutorial-venv/bin/activate\"\n",
    "!bash -c \"pip install --upgrade pip\"\n",
    "!bash -c \"pip install git+https://github.com/ExaWorks/psij-python.git\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "In PSI/J’s terminology, a [Job](https://exaworks.org/psij-python/docs/.generated/psij.html#psij.job.Job) represents an executable plus a bunch of attributes. Static job attributes such as resource requirements are defined by the [JobSpec]() at creation. Dynamic job attributes such as the [JobState]() are modified by [JobExecutors]() as the [Job]() progresses through its lifecycle.\n",
    "\n",
    "A [JobExecutor]() represents a specific *Resource Manager*, e.g. Slurm, on which the Job is being executed. Available *Resource Managers*: \n",
    "- Local\n",
    "- Slurm\n",
    "- LSF\n",
    "- Cobalt\n",
    "- PBS\n",
    "\n",
    "Generally, when jobs are submitted, they will be queued for a variable period of time, depending on how busy the target machine is. Once the Job is started, its executable is launched and runs to completion.\n",
    "\n",
    "In PSI/J, a job is submitted by [JobExecutor.submit(Job)]() which permanently binds the Job to that executor and submits it to the underlying resource manager."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage\n",
    "Creating a *single* job with PSI/J:\n",
    "1. Create a [JobExecutor]() instance.\n",
    "2. Create a [JobSpec]() object and populate it with information about your job\n",
    "3. Create a [Job]() with that [JobSpec]()\n",
    "4. Submit the [Job]() instance to the [Job](Executor)\n",
    "\n",
    "## Viewing Job Status\n",
    "To view a jobs' status, you can use `print(str(Job.status))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status Stages:\n",
      "\tPrior to submitting:  JobStatus[NEW, time=1673041703.5975358]\n",
      "\tAfter submitting:  JobStatus[ACTIVE, time=1673041703.6158385]\n",
      "\tOnce completed:  JobStatus[COMPLETED, time=1673041703.7166197, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from psij import Job, JobExecutor, JobSpec\n",
    "\n",
    "environment = \"local\"\n",
    "executable = \"/bin/date\"\n",
    "ex = JobExecutor.get_instance(environment)\n",
    "job = Job(JobSpec(executable=executable))\n",
    "\n",
    "print(\"Job Status Stages:\")\n",
    "print(\"\\tPrior to submitting: \", str(job.status))\n",
    "ex.submit(job)\n",
    "print(\"\\tAfter submitting: \", str(job.status))\n",
    "time.sleep(1)\n",
    "print(\"\\tOnce completed: \", str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Jobs\n",
    "This section will show you how to submit *multiple* jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting jobs: \n",
      "JobStatus[NEW, time=1673041705.85077]\n",
      "JobStatus[NEW, time=1673041705.868976]\n",
      "JobStatus[NEW, time=1673041705.8858225]\n",
      "JobStatus[NEW, time=1673041705.9006584]\n",
      "JobStatus[NEW, time=1673041705.915577]\n",
      "JobStatus[NEW, time=1673041705.9316385]\n",
      "JobStatus[NEW, time=1673041705.9460511]\n",
      "JobStatus[NEW, time=1673041705.9592762]\n",
      "JobStatus[NEW, time=1673041705.9721496]\n",
      "JobStatus[NEW, time=1673041705.984657]\n",
      "\n",
      "Completed Jobs: \n",
      "JobStatus[COMPLETED, time=1673041705.9202194, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041705.9203172, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041705.9246562, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.1285424, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.1286585, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.1287165, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.1287718, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.1288874, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.128965, exit_code=0]\n",
      "JobStatus[COMPLETED, time=1673041706.1290245, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "from psij import Job, JobExecutor, JobSpec\n",
    "from psij import JobState\n",
    "\n",
    "executable = \"/bin/date\"\n",
    "ex = JobExecutor.get_instance(environment)\n",
    "\n",
    "jobs = []\n",
    "\n",
    "print(\"Submitting jobs: \")\n",
    "for _ in range(10):\n",
    "    job = Job(JobSpec(executable=executable))\n",
    "    print(str(job.status))\n",
    "    jobs.append(job)\n",
    "    ex.submit(job)\n",
    "\n",
    "time.sleep(1)\n",
    "print(\"\\nCompleted Jobs: \")\n",
    "_ = [print(str(job.status)) for job in jobs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every instance of `JobExecutor` can handle an abitrar number of submitted jobs. For reference, we have tested it with up to 64,000 jobs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting for Completion\n",
    "To wait for a job to complete once it has been submitted, it suffices to call the [wait]() method with no arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<psij.job_status.JobStatus at 0x2aaadc91a898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from psij import Job, JobSpec\n",
    "\n",
    "job = Job(JobSpec(executable=\"/bin/date\"))\n",
    "ex.submit(job)\n",
    "job.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [wait]() call will return once the job has reached a terminal state, which almost always means that it finished or was cancelled.\n",
    "\n",
    "To distinguish jobs that complete successfully from ones that fail or are cancelled, fetch the status of the job after calling [wait]():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[COMPLETED, time=1673041709.5348377, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "job.wait()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring a Job\n",
    "The previous examples specify `executable='/bin/date'` tells PSI/J that we want to run the `/bin/date` command. The superclass is `JobSpec`, which allows you to configure the following parameters used in the instance of `Job`:\n",
    "- arguements for teh job executable\n",
    "- environment the job is runnning in\n",
    "- destination for standard output and error streams\n",
    "- resource requirements for the job's execution\n",
    "- accounting details to be used\n",
    "\n",
    "Relevant Docs: [JobSpec]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Arguements\n",
    "The executable’s command line arguments to be used for a job are specified as a list of strings in the arguments attribute of the `JobSpec` class. For example, our previous /bin/date job could be changed to request UTC time formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[NEW, time=1673041714.1849961]\n",
      "JobStatus[FAILED, time=1673041714.3477576, message=_PSI_J_LAUNCHER_DONE, exit_code=1]\n"
     ]
    }
   ],
   "source": [
    "environment = 'local'\n",
    "ex = JobExecutor.get_instance(environment)\n",
    "job = Job(JobSpec(executable='/bin/date', arguments=['-utc', '--debug']))\n",
    "\n",
    "print(str(job.status))\n",
    "ex.submit(job)\n",
    "job.wait()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: *JobSpec* can also be added incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[NEW, time=1673041716.008083]\n",
      "JobStatus[COMPLETED, time=1673041716.1515958, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "from psij import JobSpec\n",
    "\n",
    "spec = JobSpec()\n",
    "spec.executable = '/bin/date'\n",
    "spec.arguments = ['-u']\n",
    "job = Job(spec)\n",
    "\n",
    "print(str(job.status))\n",
    "ex.submit(job)\n",
    "job.wait()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Environment\n",
    "The job environment sets the environment variables for a job before it is launched. This is the equivalent of exporting `FOO=bar` on the command line before running a command. These environment variables are specified as a dictionary of string key/value pairs:\n",
    "\n",
    "*Note: Environment variables specified this way will overwrite settings from your shell initialization files (e.g., ~/.bashrc), including from any modules loaded in the default shell environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[NEW, time=1673041717.778529]\n",
      "JobStatus[COMPLETED, time=1673041717.9551513, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "from psij import JobSpec\n",
    "\n",
    "spec = JobSpec()\n",
    "spec.executable = '/bin/date'\n",
    "spec.environment = {'TZ': 'America/Los_Angeles'}\n",
    "job = Job(spec)\n",
    "\n",
    "print(str(job.status))\n",
    "ex.submit(job)\n",
    "job.wait()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Stdio\n",
    "Standard output and standard error streams of the job can be individually redirected to files by setting the stdout_path and stderr_path attributes:\n",
    "\n",
    "The job’s standard input stream can also be redirected to read from a file, by setting the `spec.stdin_path` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[NEW, time=1673041719.5712633]\n",
      "JobStatus[COMPLETED, time=1673041719.7589772, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "from psij import JobSpec\n",
    "\n",
    "spec = JobSpec()\n",
    "spec.executable = '/bin/date'\n",
    "spec.stdout_path = '/tmp/date.out'\n",
    "spec.stderr_path = '/tmp/date.err'\n",
    "job = Job(spec)\n",
    "\n",
    "print(str(job.status))\n",
    "ex.submit(job)\n",
    "job.wait()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Resources\n",
    "A job submitted to a cluster is allocated a specific set of resources to run on. The amount and type of resources are defined by a resource specification `ResourceSpec` which becomes a part of the job specification. The resource specification supports the following attributes:\n",
    "\n",
    "* `node_count`: allocate that number of compute nodes to the job. All cpu-cores and gpu-cores on the allocated node can be exclusively used by the submitted job.\n",
    "\n",
    "* `processes_per_node`: on the allocated nodes, execute that given number of processes.\n",
    "\n",
    "* `process_count`: the total number of processes (MPI ranks) to be started\n",
    "\n",
    "* `cpu_cores_per_process`: the number of cpu cores allocated to each launched process. PSI/J uses the system definition of a cpu core which may refer to a physical cpu core or to a virtual cpu core, also known as a hardware thread.\n",
    "\n",
    "* `gpu_cores_per_process`: the number of gpu cores allocated to each launched process. The system definition of an gpu core is used, but usually refers to a full physical GPU.\n",
    "\n",
    "* `exclusive_node_use`: When this boolean flag is set to True, then PSI/J will ensure that no other jobs, neither of the same user nor of other users of the same system, will run on any of the compute nodes on which processes for this job are launched.\n",
    "\n",
    "A resource specification does not need to define all available attributes. In fact, an empty resource spec is valid as it refers to a single process being launched on a single cpu core.\n",
    "\n",
    "The user should also take care not to define contradictory statements. For example, the following specification cannot be enacted by PSI/J as the specified node count contradicts the value of `process_count / processes_per_node`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[NEW, time=1673041721.837711]\n",
      "JobStatus[FAILED, time=1673041721.9633806, message=_PSI_J_LAUNCHER_DONE, exit_code=127]\n"
     ]
    }
   ],
   "source": [
    "from psij import JobSpec, ResourceSpecV1\n",
    "\n",
    "spec = JobSpec()\n",
    "spec.executable = '/bin/stress'\n",
    "spec.resource_spec = ResourceSpecV1(node_count=2, processes_per_node=2,\n",
    "        process_count=4)\n",
    "job = Job(spec)\n",
    "\n",
    "print(str(job.status))\n",
    "ex.submit(job)\n",
    "job.wait()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processes versus ranks\n",
    "All processes of the job will share a single MPI communicator (*MPI_COMM_WORLD*), independent of their placement, and the term *rank* (which usually refers to an MPI rank) is thus equivalent. However, jobs started with a single process instance may, depending on the executor implementation, not get an MPI communicator. How Jobs are launched can be specified by the launcher attribute of the `JobSpec`, as documented below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Methods\n",
    "To specify how the processes in your job should be started once resources have been allocated for it, pass the name of a launcher (e.g. `\"mpirun\"`, `\"srun\"`, etc.) like so: `JobSpec(..., launcher='srun')`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling Information\n",
    "To specify resource-manager-specific information, like queues/partitions, runtime, and so on, create a [JobAttributes]() and set it with `JobSpec(..., attributes=my_job_attributes)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[NEW, time=1673041724.589741]\n",
      "JobStatus[COMPLETED, time=1673041724.7682035, exit_code=0]\n"
     ]
    }
   ],
   "source": [
    "from psij import Job, JobExecutor, JobSpec, JobAttributes, ResourceSpecV1\n",
    "\n",
    "environment = 'local'\n",
    "ex = JobExecutor.get_instance(environment)\n",
    "\n",
    "job = Job(\n",
    "    JobSpec(\n",
    "        executable=\"/bin/date\",\n",
    "        resources=ResourceSpecV1(node_count=1),\n",
    "        attributes=JobAttributes(\n",
    "            queue_name=\"<QUEUE_NAME>\", project_name=\"<ALLOCATION>\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(str(job.status))\n",
    "ex.submit(job)\n",
    "job.wait()\n",
    "print(str(job.status))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The <QUEUE_NAME> and <ALLOCATION> fields will depend on the system you are running on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Job State\n",
    "In all the above examples, we have submitted jobs without checking on what happened to them. Once the job has finished executing (which, for */bin/date*, should be almost as soon as the job starts) the resource manager will mark the job as complete, triggering PSI/J to do the same via the [JobStatus]() attribute of the job. `Job` state progressions follow this state model:\n",
    "\n",
    "<img src=\"./images/job_states.png\" width=\"550\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancelling a Job\n",
    "If supported by the underlying job scheduler, PSI/J jobs can be canceled by invoking the [cancel]() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus[CANCELED, time=1673041727.8790166]\n"
     ]
    }
   ],
   "source": [
    "job = Job(JobSpec(executable=\"/bin/date\"))\n",
    "ex.submit(job)\n",
    "job.cancel()\n",
    "print(str(job.status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status Callbacks\n",
    "Waiting for jobs to complete with [wait]() is fine if you don’t mind blocking while you wait for a single job to complete. However, if you want to wait on multiple jobs without blocking, or you want to get updates when jobs start running, you can attach a callback to a [JobExecutor]() which will fire whenever any job submitted to that executor changes status.\n",
    "\n",
    "To wait on multiple jobs at once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "from psij import Job, JobExecutor, JobSpec\n",
    "\n",
    "count = 3\n",
    "\n",
    "def callback(job, status):\n",
    "    global count\n",
    "\n",
    "    if status.final:\n",
    "        print(f\"Job {job} completed with status {status}\\n\")\n",
    "        count -= 1\n",
    "\n",
    "ex = JobExecutor.get_instance(\"local\")\n",
    "ex.set_job_status_callback(callback)\n",
    "\n",
    "for _ in range(count):\n",
    "    job = Job(JobSpec(executable=\"/bin/date\"))\n",
    "    ex.submit(job)\n",
    "\n",
    "while count > 0:\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status callbacks can also be set on individual jobs with [set_job_status_callback()]()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psij-ruby-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76009bf859c7381f9309fe432e50ba00bc4a43c07b3a3292e8eda4f7573404cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
