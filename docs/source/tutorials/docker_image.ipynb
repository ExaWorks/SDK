{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f680e6",
   "metadata": {},
   "source": [
    "# ExaWorks SDK Container Image\n",
    "\n",
    "The ExaWorks SDK is available in a containerized format on [dockerhub](https://hub.docker.com/r/exaworks/sdk). This docker image is a great place to start if you want to get familiar with the workflow tools comprising the SDK without the overhead of a full install.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1580ee",
   "metadata": {},
   "source": [
    "## Preparing the Conatiner Environment\n",
    "\n",
    "As we will be executing this tutorial within a container, we must first ensure that the docker daemon is running. This is sytem dependent so see documentation for your specific system. If you wish to run this note book directly, note that it does require a bash Kernal for jupyter. You can install a bash Kernal into your python virtual environment by running:\n",
    "\n",
    "```\n",
    "pip install bash_kernel\n",
    "python -m bash_kernel.install\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8555a4c",
   "metadata": {},
   "source": [
    "## Running the ExaWorks Container\n",
    "\n",
    "After preparing your enviromnment, you can pull the SDK Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba1877d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T16:59:21.644886Z",
     "start_time": "2022-03-04T16:59:20.654607Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from exaworks/sdk\n",
      "Digest: sha256:f278e43866f4e1a1da9b7d0d98f433ca88e0a598c504c2f7d3831690195d64a4\n",
      "Status: Image is up to date for exaworks/sdk:latest\n",
      "docker.io/exaworks/sdk:latest\n"
     ]
    }
   ],
   "source": [
    "docker pull exaworks/sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f65de",
   "metadata": {},
   "source": [
    "After pulling the image, you can run arbitrary commands within the container. \n",
    "\n",
    "Note that in this tutorial, we often run each command as the argument for the `docker run`. This means that no progress or state is saved between commands because the command is run on a new container based on the SDK image everytime. We use the `--login` flag because a lot of the environment is initialiazed through the `.bashrc`. Without that flag many of the packages would not work. This tutorial uses the `docker run` because of the nature of the jupyter notebook running it, and is some instances code snippets will be placed in the Markdown sections to show more complicated actions. \n",
    "\n",
    "It is recommended that instead of using `docker run` for every command, that you generate an interactive docker run using :\n",
    "\n",
    "`docker run -it exaworks/sdk bash`\n",
    "\n",
    "This will give you a shell within the container the ecexute all of the commands that fall under the `-c <command>` flag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2125b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux Version:\n",
      "commands:    \t\t0.28.0\n",
      "libflux-core:\t\t0.28.0\n",
      "build-options:\t\t+hwloc==1.11.0\n",
      "\n",
      "Parsl Version:\n",
      "1.3.0-dev\n",
      "\n",
      "Radical Pilot Version:\n",
      "1.11.2\n",
      "\n",
      "Swift-t Version:\n",
      "STC: Swift-Turbine Compiler 0.9.0\n",
      "\t for Turbine: 1.3.0\n",
      "Using Java VM:    /usr/bin/java\n",
      "Using Turbine in: /opt/swift-t/turbine\n",
      "\n",
      "Turbine 1.3.0\n",
      " installed:    /opt/swift-t/turbine\n",
      " source:       /tmp/build-swift-t/swift-t/turbine/code\n",
      " using CC:     /usr/local/bin/mpicc\n",
      " using MPI:    /usr/local/lib mpi \"OpenMPI\"\n",
      " using Tcl:    /opt/tcl-8.6.11/bin/tclsh8.6\n"
     ]
    }
   ],
   "source": [
    "echo Flux Version:\n",
    "docker run -t exaworks/sdk bash --login -c \"flux -V\"\n",
    "echo\n",
    "\n",
    "echo Parsl Version:\n",
    "docker run -t exaworks/sdk bash --login -c \"python -c 'import parsl; print(parsl.__version__)'\"\n",
    "echo\n",
    "\n",
    "echo Radical Pilot Version:\n",
    "docker run -t exaworks/sdk bash --login -c \"radical-pilot-version\"\n",
    "echo\n",
    "\n",
    "echo Swift-t Version:\n",
    "docker run -t exaworks/sdk bash --login -c \"swift-t -v\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6a6d1",
   "metadata": {},
   "source": [
    "## Running the Tests\n",
    "\n",
    "Each workflow tool has a set of tests located at `/tests/<packagename>/test.sh`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77692350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T16:59:21.862023Z",
     "start_time": "2022-03-04T16:59:21.657359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux Tests:\n",
      "Cloning into 'flux-core'...\n",
      "remote: Enumerating objects: 90454, done.\u001b[K\n",
      "remote: Counting objects: 100% (7455/7455), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2720/2720), done.\u001b[K\n",
      "remote: Total 90454 (delta 5113), reused 6693 (delta 4716), pack-reused 82999\u001b[K\n",
      "Receiving objects: 100% (90454/90454), 40.30 MiB | 13.47 MiB/s, done.\n",
      "Resolving deltas: 100% (67270/67270), done.\n",
      "write /dev/stdout: broken pipe\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "echo Flux Tests:\n",
    "docker run -t exaworks/sdk bash --login -c \"bash /tests/flux/test.sh\" | head -n 7\n",
    "echo \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84af0cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsl Tests:\n",
      "Hello World from Python!\n",
      "Hello World!\n",
      "\n",
      "Output matches\n"
     ]
    }
   ],
   "source": [
    "echo Parsl Tests:\n",
    "docker run -t exaworks/sdk bash --login -c \"bash /tests/parsl/test.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d939e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radical Pilot Tests:\n",
      "--- start MongoDB\n",
      "about to fork child process, waiting until server is ready for connections.\n",
      "forked process: 26\n",
      "child process started successfully, parent exiting\n",
      "--- smoke test\n",
      "\u001b[94m\u001b[1m\n",
      "\u001b[39m\u001b[0m\u001b[94m\u001b[1m================================================================================\n",
      "write /dev/stdout: broken pipe\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "echo Radical Pilot Tests:\n",
    "docker run -t exaworks/sdk bash --login -c \"bash /tests/rp/test.sh\" | head -n 7\n",
    "echo \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6c427f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swift-t Tests:\n",
      "+ [[ openmpi == \\o\\p\\e\\n\\m\\p\\i ]]\n",
      "+ export TURBINE_LAUNCH_OPTIONS=--allow-run-as-root\n",
      "+ TURBINE_LAUNCH_OPTIONS=--allow-run-as-root\n",
      "+ swift-t -v\n",
      "STC: Swift-Turbine Compiler 0.9.0\n",
      "\t for Turbine: 1.3.0\n",
      "Using Java VM:    /usr/bin/java\n",
      "write /dev/stdout: broken pipe\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "echo Swift-t Tests:\n",
    "docker run -t exaworks/sdk bash --login -c \"bash /tests/swift/test.sh\" | head -n 7\n",
    "echo \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31dfd5c",
   "metadata": {},
   "source": [
    "## Running the Tutorial Notebooks\n",
    "\n",
    "As of now, jupyter is not automatically included in the SDK container image, but we can easily install it! First, we have to run our container while exposing a port and mounting the directory that contains jupyter notebooks. The note books are not currently a part of the container image, so we need to make them accessible from within the conatiner using the `-v` flag. We also need to specify that we want the jupyter server to resolve on the local host at the default jupyter port. We do this by mapping the port from the host machine to the contianer with `-p 8888:8888`, and specifying the localhost ip when starting the jupyter server. \n",
    "\n",
    "```\n",
    "$ docker run -p 8888:8888 -v $(path/to/notebooks):/notebooks -it exaworks/sdk bash\n",
    "```\n",
    "\n",
    "You can then install and run jupyter.\n",
    "```\n",
    "# pip install jupyter\n",
    "# cd /notebooks\n",
    "# jupyter notebook --allow-root --ip 0.0.0.0 --no-browser\n",
    "```\n",
    "\n",
    "Then just copy the URL to your browser to view and run the notebooks. The other notebooks may have some additional prerequisites and configuration required before they can be run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553f5cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T16:59:21.878889Z",
     "start_time": "2022-03-04T16:59:21.875111Z"
    }
   },
   "source": [
    "## SDK Image Tags\n",
    "\n",
    "As a part of our CI/CD pipeline, we build the SDK with multiple build parameters, including different base operating systems, python versions, mpi flavors, and package managers. To organize these different builds, we use tags to distinguish them. When selecting an image, you can select a specific tag for a specific build spec that you want to test. The tag works as follows: `<os>_<package_manager>_<mpi_flavor>_<pyhton_version>`. Different tags can be seen [here](https://hub.docker.com/r/exaworks/sdk/tags). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d11a8d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu2004_pip_openmpi_3.8: Pulling from exaworks/sdk\n",
      "Digest: sha256:86dee9aaa13aa21715b2035945307220e560fc0141d7a08166f7bbcc4257fbed\n",
      "Status: Image is up to date for exaworks/sdk:ubuntu2004_pip_openmpi_3.8\n",
      "docker.io/exaworks/sdk:ubuntu2004_pip_openmpi_3.8\n",
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "docker pull exaworks/sdk:ubuntu2004_pip_openmpi_3.8\n",
    "docker run -t exaworks/sdk:ubuntu2004_pip_openmpi_3.8 bash --login -c \"python -V\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac289f3f",
   "metadata": {},
   "source": [
    "## SDK Base Image\n",
    "\n",
    "When building the SDK container image, we first create a minimum build base image the contains all of the dependencies for the sdk. This base image can be a great start if you want to work through building the rest of the SDK manually or just a subset of the packages. The base image can be found [here](https://hub.docker.com/r/exaworks/sdk-base). The base imge also follows the same tagging conventions as the full SDK image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6099dc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T16:59:21.936870Z",
     "start_time": "2022-03-04T16:59:21.880714Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from exaworks/sdk-base\n",
      "Digest: sha256:a40f6220a540b9e1e80250b0cdcc88503a9324d86f5db64102f5bb1dd2e9de9b\n",
      "Status: Image is up to date for exaworks/sdk-base:latest\n",
      "docker.io/exaworks/sdk-base:latest\n"
     ]
    }
   ],
   "source": [
    "docker pull exaworks/sdk-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575c970",
   "metadata": {},
   "source": [
    "## Development on the SDK Container Image\n",
    "\n",
    "The ExaWroks SDK is an opensource project, and we encourage community engagment and development on it. This includes development on the SDK container image. Be sure to checkoout our [contribution guidelines and best practices](https://github.com/ExaWorks/SDK/blob/master/CONTRIBUTING.md) before makeing changes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68109f7",
   "metadata": {},
   "source": [
    "## An Overview of the Build Process\n",
    "### Base Image\n",
    "As mentioned above, the first stop in the build process is to create a minimal build base image with all of the dependencies for the SDK. This is currently split into three different possible base dockerfiles, one for rockylinux8, on for centos7, and one for ubuntu20.04. Each of these docker files uses a combination of the os specific package manager along with a set of shared build scripts to install the dependencies. \n",
    "\n",
    "The base image is where are the different build parameters are specified. While the os determines which dockerfile the image is built from, the other build parameters are passed in during the build process. While the goal of the build parameters is to create a large build matrix where we can test all combinations of environments in our CI pipline, several of the combinations still fail to build. Development in this area could be towards fixing the build for some combinations of build parameters or by adding new ones. \n",
    "\n",
    "#### Build Parameters\n",
    "1. Operating System : centos7, rockylinux8, ubuntu20.04 \n",
    "\n",
    "    See the [SDK repo under docker/base/\\<os>](https://github.com/ExaWorks/SDK/tree/master/docker/base)\n",
    "\n",
    "\n",
    "2. Package Manager: pip, conda \n",
    "\n",
    "    See [install-python-env.sh](https://github.com/ExaWorks/SDK/blob/master/docker/base/scripts/install-python-env.sh)\n",
    "\n",
    "\n",
    "3. MPI Flavor: opmenmpi, mpich \n",
    "\n",
    "    See [install-mpi.sh](https://github.com/ExaWorks/SDK/blob/master/docker/base/scripts/install-mpi.sh)\n",
    "\n",
    "\n",
    "4. Python Version: 3.7, 3.8, 3.9 \n",
    "\n",
    "    See [install-python.sh](https://github.com/ExaWorks/SDK/blob/master/docker/base/scripts/install-python-env.sh) or if conda, see [install-python-env.sh](https://github.com/ExaWorks/SDK/blob/master/docker/base/scripts/install-python-env.sh)\n",
    "\n",
    "### Workflow Tool Images\n",
    "Each workflow tool is installed using its own dockerfile and any additional build scripts. Each one has an argument for base image, which sets the `FROM` line in the dockerfile. Development in this area would be to expand the tests for a specific workflow tool or to add a new tool to the SDK image. \n",
    "\n",
    "#### Testing \n",
    "Each workflow tool has its own set of tests, which are added to the SDK Image under `/tests/<package>/` and are inititiated by a `test.sh` in that directory. These tests give the code teams key insights on where bugs or failures might exist in their codesbases and how to fix them. Our CI pipeline runs these tests then exports the data to our [testing dashbaord](https://testing.exaworks.org/summary.html). These tests range from full unit and integration tests to simple sanity checks, and more additions or use cases are always welcome. \n",
    "\n",
    "#### Adding a New Worflow Tool\n",
    "We are encouraging community engagement and wish to expand the ExaWorks SDK with new workflow tools. To do so, we also need to expand the SDK Image. We do this by adding a new directory under [docker in the SDK repo](https://github.com/ExaWorks/SDK/tree/master/docker) for the dockerfile and any related build scripts. All the of specifc images should be able to be built directly from the SDK Base Image or from any other SDK image. We use the build argument of `BASE_IMAGE` to set which SDK image we are building from. \n",
    "```\n",
    "ARG BASE_IMAGE=exaworks/sdk-base\n",
    "FROM ${BASE_IMAGE}\n",
    "```\n",
    "Aside from just adding the build files for the new tool, be sure to add in tests as well! \n",
    "\n",
    "#### Updating the CI Pipline\n",
    "After adding a new tool to the SDK, also be sure to update the CI pipeline to include builds for that new workflow tool. This can be done by editing the [ci.yml](https://github.com/ExaWorks/SDK/blob/master/.github/workflows/ci.yml) under the build and tests stages. During the build stage, we add new worflow tools one at a time and update the tag with the new tool being added. For Example:\n",
    "```\n",
    "docker build \\\n",
    "          -t rp_parsl_swift_flux:${{ env.DOCKER_TAG }} \\\n",
    "          --build-arg BASE_IMAGE=rp_parsl_swift:${{ env.DOCKER_TAG }} \\\n",
    "          docker/flux\n",
    "```\n",
    "You can see that in this part of the build process, we have already added Radical Pilot, Parsl, and Swift-t to the SDK Image, and we are currently adding in flux. The `${{ env.DOCKER_TAG }}` represents the combination of build arguments from the base image. Be sure to add any new image builds before the last one containing the integration and to update the base image for the integration build. To update the tests, simply add in the new tool in for loop. \n",
    "```\n",
    "for core in flux parsl rp swift flux-parsl <new-tool>\n",
    "        do\n",
    "          ...\n",
    "        done\n",
    "```\n",
    "    \n",
    "When all changes appear to pass in the [ci.yml](https://github.com/ExaWorks/SDK/blob/master/.github/workflows/ci.yml), apply those same changes to the build process in [deploy.yml](https://github.com/ExaWorks/SDK/blob/master/.github/workflows/deploy.yml). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7180340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
